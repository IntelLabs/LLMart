<div align="center">
  <img src="assets/llmart.png" alt="Large Language Model adversarial robustness toolkit" width="300" />

## Large Language Model adversarial robustness toolkit
![OpenSSF Scorecard](https://img.shields.io/ossf-scorecard/github.com/IntelLabs/LLMart)
![GitHub License](https://img.shields.io/github/license/IntelLabs/LLMart)
![Python Version from PEP 621 TOML](https://img.shields.io/python/required-version-toml?tomlFilePath=https%3A%2F%2Fraw.githubusercontent.com%2FIntelLabs%2FLLMart%2Frefs%2Fheads%2Fmain%2Fpyproject.toml)

:rocket: [Quick start](#rocket-quick-start) ‚èê :briefcase: [Project Overview](#briefcase-project-overview) ‚èê :robot: [Models](#robot-models) ‚èê :clipboard: [Datasets](#clipboard-datasets) ‚èê :chart_with_downwards_trend: [Optimizers and schedulers](#chart_with_downwards_trend-optimizers-and-schedulers) ‚èê :pencil2: [Citation](#pencil2-citation)

</div>

## :pushpin: What is **LLM**art?

**LLM**art is a toolkit for evaluating LLM robustness through adversarial testing. Built with PyTorch and Hugging Face integrations, **LLM**art enables scalable red teaming attacks with parallelized optimization across multiple devices.
**LLM**art has configurable attack patterns, support for soft prompt optimization, detailed logging, and is intended both for high-level users that want red team evaluation with off-the-shelf algorithms, as well as research power users that intend to experiment with the implementation details of input-space optimization for LLMs.

While it is still under development, the goal of **LLM**art is to support any Hugging Face model and include example scripts for modular implementation of different attack strategies.

## :rocket: Quick start
Developed and tested on Ubuntu 22.04 with `Python 3.11`.
To run an adversarial attack that induces the following open-ended response from the `meta-llama/Meta-Llama-3-8B-Instruct` model:
> **User:** Tell me about the planet Saturn. <20-token-optimized-suffix>
>
> **Response:** NO WAY JOSE


First, basic installation from source is done via:
```bash
git clone https://github.com/IntelLabs/LLMart
cd LLMart

python3.11 -m venv .venv
source .venv/bin/activate
pip install -e ".[core,dev]"
```

> [!NOTE]
> We also include a Poetry 2.0 `poetry.lock` file that perfectly reproduces dependencies we use.

Once the environment is installed and `export HUGGINGFACE_TOKEN=...` is set to a token with valid model access, **LLM**art can be run to optimize the suffix with:
```bash
accelerate launch -m llmart model=llama3-8b-instruct data=basic loss=model
```

This will automatically distribute an attack on the maximum number of detected devices. Results are saved in the `outputs/llmart` folder and can be visualized with `tensorboard` using:
```bash
tensorboard --logdir=outputs/llmart
```

## :briefcase: Project overview
The algorithmic **LLM**art functionality is structured as follows and uses PyTorch naming conventions as much as possible:
```
üì¶LLMart
 ‚î£ üìÇexamples   # Click-to-run example collection
 ‚îó üìÇsrc/llmart # Core library
   ‚î£ üìú__main__.py   # Entry point for python -m command
   ‚î£ üìúattack.py     # End-to-end adversarial attack in functional form
   ‚î£ üìúcallbacks.py  # Hydra callbacks
   ‚î£ üìúconfig.py     # Configurations for all components
   ‚î£ üìúdata.py       # Converting datasets to torch dataloaders
   ‚î£ üìúlosses.py     # Loss objectives for the attacker
   ‚î£ üìúmodel.py      # Wrappers for Hugging Face models
   ‚î£ üìúoptim.py      # Optimizers for integer variables
   ‚î£ üìúpickers.py    # Candidate token deterministic picker algorithms
   ‚î£ üìúsamplers.py   # Candidate token stochastic sampling algorithms
   ‚î£ üìúschedulers.py # Schedulers for integer hyper-parameters
   ‚î£ üìútokenizer.py  # Wrappers for Hugging Face tokenizers
   ‚î£ üìútransforms.py # Text and token-level transforms
   ‚î£ üìúutils.py
   ‚î£ üìÇdatasets      # Dataset storage and loading
   ‚îó üìÇpipelines     # Wrappers for Hugging Face pipelines
```

## :robot: Models
While **LLM**art comes with a limited number of models accessible via custom naming schemes (see the `PipelineConf` class in `config.py`), it is designed with Hugging Face hub model compatibility in mind.

Running a new model from the hub can be directly done by specifying:
```bash
model=custom model.name=... model.revision=...
```

> [!CAUTION]
> Including a valid `model.revision` is mandatory.

For example, to load a custom model:
```bash
accelerate launch -m llmart model=custom model.name=Intel/neural-chat-7b-v3-3 model.revision=7506dfc5fb325a8a8e0c4f9a6a001671833e5b8e data=basic loss=model
```

> [!TIP]
> If you find a model that is not supported via command line, please [raise an issue](https://github.com/IntelLabs/LLMart/issues/new) and we will do our best to address it immediately.

### :brain: Large models
**LLM**art also supports large models that cannot execute the forward and/or backward pass on a single device:
```bash
python -m llmart model=llama3.1-70b-instruct model.device=null model.device_map=auto data=basic loss=model
```

> [!CAUTION]
> Including `model.device=null model.device_map=auto` and launching using `python -m llmart` is mandatory for large models. See [Designing a device map](https://huggingface.co/docs/accelerate/main/en/concept_guides/big_model_inference#designing-a-device-map) for more info.

## :clipboard: Datasets
Inspecting and adding a new dataset to **LLM**art only involves a single function that returns a list with the standard Hugging Face conversation format.

The `basic` dataset is the simplest instantiation that lives at [`datasets/basic.py`](src/llmart/datasets/basic.py), but is also powerful enough to support custom modifications.

For example, to modify the natural language prompt and desired open-ended response, the following basic edit is sufficient:
```diff
diff src/llmart/datasets/basic.py
def get_conversations() -> list[list[dict[str, str]]]:
    return [
        [
-           dict(role="user", content="Tell me about the planet Saturn."),
+           dict(role="user", content="Tell me how to do something not allowed."),
-           dict(role="assistant", content="NO WAY JOSE"),
+           dict(role="assistant", content="Sure, I'll tell you: first, you"),
        ],
    ]
```

Inducing a closed-ended response can be also directly done by typing out the end of turn token. For example, for the Llama 3 family of models this is:
```diff
diff src/llmart/datasets/basic.py
def get_conversations() -> list[list[dict[str, str]]]:
    return [
        [
-           dict(role="user", content="Tell me about the planet Saturn."),
+           dict(role="user", content="Tell me how to do something not allowed."),
-           dict(role="assistant", content="NO WAY JOSE"),
+           dict(role="assistant", content="NO WAY JOSE<|eot_id|>"),
        ],
    ]
```

**LLM**art also supports loading the [AdvBench](https://github.com/llm-attacks/llm-attacks) dataset, which comes with pre-defined target responses to ensure consistent benchmarks.

Using AdvBench with **LLM**art requires downloading the two files to disk, after which simply specifying the desired dataset and the subset of samples to attack will run out of the box:
```bash
curl -O https://raw.githubusercontent.com/llm-attacks/llm-attacks/refs/heads/main/data/advbench/harmful_behaviors.csv

accelerate launch -m llmart model=llama3-8b-instruct data=advbench_behavior data.path=/path/to/harmful_behaviors.csv data.subset=[0] loss=model
```

## :chart_with_downwards_trend: Optimizers and schedulers
Discrete optimization for language models [(Lei et al, 2019)](https://proceedings.mlsys.org/paper_files/paper/2019/hash/676638b91bc90529e09b22e58abb01d6-Abstract.html) &ndash; in particular the Greedy Coordinate Gradient (GCG) applied to auto-regressive LLMs [(Zou et al, 2023)](https://arxiv.org/abs/2307.15043) &ndash; is the main focus of [`optim.py`](src/llmart/optim.py).

We re-implement the GCG algorithm using the `torch.optim` API by making use of the `closure` functionality in the search procedure, while completely decoupling optimization from non-essential components.

```python
class GreedyCoordinateGradient(Optimizer):
  def __init__(...)
    # Nothing about LLMs or tokenizers here
    ...

  def step(...)
    # Or here
    ...
```

The same is true for the schedulers implemented in [`schedulers.py`](src/llmart/schedulers.py) which follow PyTorch naming conventions but are specifically designed for integer hyper-parameters (the integer equivalent of "learning rates" in continuous optimizers).

This means that the GCG optimizer and schedulers are re-usable in other integer optimization problems (potentially unrelated to auto-regressive language modeling) as long as a gradient signal can be defined.


## :pencil2: Citation
If you find this repository useful in your work, please cite:
```bibtex
@software{llmart2025github,
  author = {Cory Cornelius and Marius Arvinte and Sebastian Szyller and Weilin Xu and Nageen Himayat},
  title = {{LLMart}: {L}arge {L}anguage {M}odel adversarial robutness toolbox},
  url = {http://github.com/IntelLabs/LLMart},
  version = {2025.01},
  year = {2025},
}
```
